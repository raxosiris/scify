{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without NEL for now, just pattern matching, and linguistic heuristics to remove unpromising sentences from the pipeline\n",
    "\n",
    "\n",
    "\n",
    "[ 1 ] Sentence Level check Filter before NER/NEL/neg Basic Tagger + Tokenizer\n",
    "    => Len, SDP-len, Dep_complexity. TRIGGER WORDS! (cause, inhibit, therefore)\n",
    " \n",
    "[ 2 ] Remaining sentences (with doc context needed for NER context??) =>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from negspacy.negation import Negex #https://github.com/jenojp/negspacy\n",
    "from spacy.pipeline import EntityRuler\n",
    "from extractacy.extract import ValueExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scify.nlp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_sci_md\")\n",
    "negex = Negex(nlp, ent_types=[\"PERSON\",\"ORG\"])\n",
    "nlp.add_pipe(negex, last=True) #works on an per entity basis. If causal phrases become entities?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[is a really nice, green apple]\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"This is a really nice, green apple. One apple a day ...!\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "pattern = [{'ORTH': 'is'}]\n",
    "for i in range(0,5): #aribtrary number of wild cards in between\n",
    "    pattern.append({\"OP\": \"?\"}) \n",
    "pattern.append({\"ORTH\": \"apple\"})\n",
    "\n",
    "matcher.add('test', None, pattern)\n",
    "spans = [doc[start:end] for match_id, start, end in matcher(doc)]\n",
    "for span in spans:\n",
    "    print(spans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Doc.set_extension('my_ents', default=None)\n",
    "\n",
    "#add to pipeline (for multiple docs...merging)\n",
    "def move_ents_to_attr(doc):\n",
    "    if doc._.my_ents is None:\n",
    "        doc._.my_ents = []\n",
    "    doc._.my_ents.extend(doc.ents)\n",
    "    doc.ents = []\n",
    "    return doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pseudo_patterns': [no further,\n",
       "  not able to be,\n",
       "  not certain if,\n",
       "  not certain whether,\n",
       "  not necessarily,\n",
       "  without any further,\n",
       "  without difficulty,\n",
       "  without further,\n",
       "  might not,\n",
       "  not only,\n",
       "  no increase,\n",
       "  no significant change,\n",
       "  no change,\n",
       "  no definite change,\n",
       "  not extend,\n",
       "  not cause,\n",
       "  not certain if,\n",
       "  not certain whether,\n",
       "  gram negative,\n",
       "  not rule out,\n",
       "  not ruled out,\n",
       "  not been ruled out,\n",
       "  not drain,\n",
       "  no suspicious change,\n",
       "  no interval change,\n",
       "  no significant interval change],\n",
       " 'preceding_patterns': [absence of,\n",
       "  declined,\n",
       "  denied,\n",
       "  denies,\n",
       "  denying,\n",
       "  no sign of,\n",
       "  no signs of,\n",
       "  not,\n",
       "  not demonstrate,\n",
       "  symptoms atypical,\n",
       "  doubt,\n",
       "  negative for,\n",
       "  no,\n",
       "  versus,\n",
       "  without,\n",
       "  doesn't,\n",
       "  doesnt,\n",
       "  don't,\n",
       "  dont,\n",
       "  didn't,\n",
       "  didnt,\n",
       "  wasn't,\n",
       "  wasnt,\n",
       "  weren't,\n",
       "  werent,\n",
       "  isn't,\n",
       "  isnt,\n",
       "  aren't,\n",
       "  arent,\n",
       "  cannot,\n",
       "  can't,\n",
       "  cant,\n",
       "  couldn't,\n",
       "  couldnt,\n",
       "  never,\n",
       "  patient was not,\n",
       "  without indication of,\n",
       "  without sign of,\n",
       "  without signs of,\n",
       "  without any reactions or signs of,\n",
       "  no complaints of,\n",
       "  no evidence of,\n",
       "  no cause of,\n",
       "  evaluate for,\n",
       "  fails to reveal,\n",
       "  free of,\n",
       "  never developed,\n",
       "  never had,\n",
       "  did not exhibit,\n",
       "  rules out,\n",
       "  rule out,\n",
       "  rule him out,\n",
       "  rule her out,\n",
       "  rule patient out,\n",
       "  rule the patient out,\n",
       "  ruled out,\n",
       "  ruled him outruled her out,\n",
       "  ruled patient out,\n",
       "  ruled the patient out,\n",
       "  r/o,\n",
       "  ro],\n",
       " 'following_patterns': [declined,\n",
       "  unlikely,\n",
       "  was not,\n",
       "  were not,\n",
       "  wasn't,\n",
       "  wasnt,\n",
       "  weren't,\n",
       "  werent,\n",
       "  was ruled out,\n",
       "  were ruled out,\n",
       "  free],\n",
       " 'termination_patterns': [although,\n",
       "  apart from,\n",
       "  as there are,\n",
       "  aside from,\n",
       "  but,\n",
       "  except,\n",
       "  however,\n",
       "  involving,\n",
       "  nevertheless,\n",
       "  still,\n",
       "  though,\n",
       "  which,\n",
       "  yet,\n",
       "  still,\n",
       "  cause for,\n",
       "  cause of,\n",
       "  causes for,\n",
       "  causes of,\n",
       "  etiology for,\n",
       "  etiology of,\n",
       "  origin for,\n",
       "  origin of,\n",
       "  origins for,\n",
       "  origins of,\n",
       "  other possibilities of,\n",
       "  reason for,\n",
       "  reason of,\n",
       "  reasons for,\n",
       "  reasons of,\n",
       "  secondary to,\n",
       "  source for,\n",
       "  source of,\n",
       "  sources for,\n",
       "  sources of,\n",
       "  trigger event for]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#negex.get_patterns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import eq, ge, le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = {\n",
    "    \n",
    "    LEN_TRESH: 15,\n",
    "    SUBTREE_LEN_TRESH: 6,\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Your mama is fat and you are fat too\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(sent) > LEN_TRESH for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
